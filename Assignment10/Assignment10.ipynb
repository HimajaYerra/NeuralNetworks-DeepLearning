{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Video Link:https://drive.google.com/file/d/1F7LVckNMizXEhHqd68peuZrZDPAr3XFl/view?usp=sharing"
      ],
      "metadata": {
        "id": "HrS5-xFTzMBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "WYc8edpppnSW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Sentiment.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]"
      ],
      "metadata": {
        "id": "0WsrzL1ZqCzT"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
      ],
      "metadata": {
        "id": "-56s0eP2qDer"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')"
      ],
      "metadata": {
        "id": "dlx4D1dEqF6e"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)"
      ],
      "metadata": {
        "id": "_1lw3YS4qIgX"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(X)\n",
        "\n",
        "embed_dim = 129\n",
        "lstm_out = 196"
      ],
      "metadata": {
        "id": "ZdgeO8kCqIl1"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "metadata": {
        "id": "A4YJwVqBwy4D"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified the model to take embed_dim & lstm_out as parameters to be able to do gridsearch"
      ],
      "metadata": {
        "id": "X8-vOKcwwGtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to create the model\n",
        "def create_model(embed_dim, lstm_out):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "1ySvyWDku-Fd"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the KerasClassifier object for use with GridSearchCV\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b59OXBgU8oYI",
        "outputId": "180d18c2-4fb4-46be-e0ce-1f809760996e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-99-48d9636a61df>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters to search over\n",
        "param_grid = {\n",
        "    'embed_dim': [64, 128],\n",
        "    'lstm_out': [128, 196]\n",
        "}"
      ],
      "metadata": {
        "id": "ZEFClHWw8gfF"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the GridSearchCV object\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=2,scoring='neg_log_loss')\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-9HK8MH8kI0",
        "outputId": "b9a73838-b6bd-418d-b41b-b8f29874319a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "146/146 [==============================] - 16s 90ms/step - loss: 0.8719 - accuracy: 0.6263\n",
            "146/146 [==============================] - 2s 12ms/step\n",
            "[CV] END .........................embed_dim=64, lstm_out=128; total time=  25.9s\n",
            "146/146 [==============================] - 15s 83ms/step - loss: 0.8969 - accuracy: 0.6090\n",
            "146/146 [==============================] - 2s 10ms/step\n",
            "[CV] END .........................embed_dim=64, lstm_out=128; total time=  17.0s\n",
            "146/146 [==============================] - 24s 145ms/step - loss: 0.8761 - accuracy: 0.6242\n",
            "146/146 [==============================] - 3s 18ms/step\n",
            "[CV] END .........................embed_dim=64, lstm_out=196; total time=  47.0s\n",
            "146/146 [==============================] - 26s 153ms/step - loss: 0.8925 - accuracy: 0.6088\n",
            "146/146 [==============================] - 3s 20ms/step\n",
            "[CV] END .........................embed_dim=64, lstm_out=196; total time=  48.1s\n",
            "146/146 [==============================] - 17s 95ms/step - loss: 0.8689 - accuracy: 0.6287\n",
            "146/146 [==============================] - 2s 11ms/step\n",
            "[CV] END ........................embed_dim=128, lstm_out=128; total time=  20.0s\n",
            "146/146 [==============================] - 17s 93ms/step - loss: 0.8772 - accuracy: 0.6187\n",
            "146/146 [==============================] - 2s 12ms/step\n",
            "[CV] END ........................embed_dim=128, lstm_out=128; total time=  19.4s\n",
            "146/146 [==============================] - 27s 165ms/step - loss: 0.8606 - accuracy: 0.6313\n",
            "146/146 [==============================] - 4s 28ms/step\n",
            "[CV] END ........................embed_dim=128, lstm_out=196; total time=  49.7s\n",
            "146/146 [==============================] - 29s 175ms/step - loss: 0.8750 - accuracy: 0.6182\n",
            "146/146 [==============================] - 4s 22ms/step\n",
            "[CV] END ........................embed_dim=128, lstm_out=196; total time=  34.9s\n",
            "291/291 [==============================] - 31s 98ms/step - loss: 0.8265 - accuracy: 0.6436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best hyperparameters and score\n",
        "print(\"Best parameters: \", grid_result.best_params_)\n",
        "print(\"Best score: \", grid_result.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrUh-5tMy8Ri",
        "outputId": "ddd27789-7825-4cd5-f49e-3f92dc510993"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'embed_dim': 128, 'lstm_out': 128}\n",
            "Best score:  -0.7970625649995492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifying the model with best parameters obtained from gridsearch"
      ],
      "metadata": {
        "id": "d0mxQt6SwW3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train the model with the best hyperparameters\n",
        "best_params = grid_result.best_params_\n",
        "model = create_model(best_params['embed_dim'], best_params['lstm_out'])\n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=32, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hdae0l-z50j",
        "outputId": "e43cfa99-e344-4a64-c53c-bb825a3c9f5c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 - 29s - loss: 0.8246 - accuracy: 0.6448 - 29s/epoch - 98ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9d9d5f7610>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=32)\n",
        "print(\"Test loss: \", score)\n",
        "print(\"Test accuracy: \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKE7xlPvzBg6",
        "outputId": "6f6a705c-75da-48d7-94e4-6ae92dbb0e28"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144/144 - 2s - loss: 0.7687 - accuracy: 0.6767 - 2s/epoch - 14ms/step\n",
            "Test loss:  0.7686622142791748\n",
            "Test accuracy:  0.6767147183418274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"A lot of good things are happening. We are respected again throughout the world, and that's a great thing.@realDonaldTrump\""
      ],
      "metadata": {
        "id": "-kAb8wNHr-Kr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your new text here\n",
        "\n",
        "# Preprocess the new text\n",
        "test_text = test_text.lower()\n",
        "test_text = re.sub('[^a-zA-z0-9\\s]', '', test_text)\n",
        "test_text_seq = tokenizer.texts_to_sequences([test_text])\n",
        "test_text_padded = pad_sequences(test_text_seq, maxlen=X.shape[1], padding='post')\n",
        "\n",
        "# Predict the sentiment of the new text\n",
        "predicted_sentiment = model.predict(test_text_padded)[0]\n",
        "predicted_label = labelencoder.inverse_transform([np.argmax(predicted_sentiment)])\n",
        "print(\"Predicted sentiment: \", predicted_label[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw-bVegms-Jm",
        "outputId": "c5b66fbf-a701-4544-8c72-0acde38d9dd1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 267ms/step\n",
            "Predicted sentiment:  Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5I_f54YmtDfc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}